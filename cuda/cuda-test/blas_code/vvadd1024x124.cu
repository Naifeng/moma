
/*
 * This code was generated by Spiral 8.5.1, www.spiral.net
 */

#include <stdint.h>

void init_nttmpcuda() {
    /* skip */
}

__global__ void ker_code0(uint64_t  *X, uint64_t  *Y, uint64_t *modulus, uint64_t  *twiddles, uint64_t *mu) {
    int a107, a108, a109, a110, a111, a112, a113, a114, 
            b5, c2, i38;
    uint64_t a84, a91, d4, d5, d6, t18, t19;
    uint128_t s28, s29, s30;
    __shared__ uint64_t T1[8];
    a107 = (1024*blockIdx.x);
    a108 = (a107 + threadIdx.x);
    /* Begin of MPModAdd 64 */
    /* MPAddDDD 64 */
    a109 = (2*a108);
    a110 = (a109 + 1);
    s28 = (((uint128_t ) X[a110]) + ((uint128_t ) twiddles[a110]));
    t18 = ((uint64_t ) s28);
    c2 = (s28 >> 64);
    s29 = (((uint128_t ) X[a109]) + ((uint128_t ) twiddles[a109]));
    s30 = (((uint128_t ) s29) + ((uint128_t ) c2));
    t19 = ((uint64_t ) s30);
    /* Begin of MPModDD */
    /* MPLessThan 64 */
    a84 = modulus[0];
    a111 = ((a84 < t19));
    a112 = ((a84 == t19));
    a91 = modulus[1];
    a113 = ((a91 < t18));
    a114 = ((a112) && (a113));
    i38 = ((a111) || (a114));
    /* Begin of MPSubDDD 64 */
    d4 = (t18 - a91);
    b5 = ((t18 < a91));
    d5 = (t19 - a84);
    d6 = (d5 - b5);
    /* End of MPSubDDD 64 */
    Y[a109] = ((i38) ? (d6) : (t19));
    Y[a110] = ((i38) ? (d4) : (t18));
    /* End of MPModDD */
    /* End of MPModAdd 64 */
    __syncthreads();
}

void nttmpcuda(uint64_t  *Y, uint64_t  *X, uint64_t modulus[2], uint64_t  *twiddles, uint64_t mu[2]) {
    dim3 b3(1024, 1, 1), g1(2, 1, 1);
    ker_code0<<<g1, b3>>>(X, Y, modulus, twiddles, mu);
}

void destroy_nttmpcuda() {
    /* skip */
}
